{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import dct\n",
    "import matplotlib.pyplot as plt\n",
    "from python_speech_features.base import mfcc\n",
    "import seq2seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root = './'\n",
    "keep_prob = 0.8\n",
    "max_output_length = \n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = tf.gfile.Open(root + 'wsj0/transcripts/wsj0/wsj0.trans')\n",
    "\n",
    "def get_next_input():\n",
    "    trans = out_file.readline()\n",
    "    cont, file = trans.split('(')\n",
    "    file = file[:-2]\n",
    "    sample_rate, signal = scipy.io.wavfile.read(FileOpen(root + file.rstrip('\\n'), 'rb'))\n",
    "    X = onehot(list(cont))\n",
    "    Y = mfcc(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A custom class inheriting tf.gfile.Open for providing seek with whence\n",
    "class FileOpen(tf.gfile.Open):\n",
    "    def seek(self, position, whence = 0):\n",
    "        if (whence == 0):\n",
    "            tf.gfile.Open.seek(self, position)\n",
    "        elif (whence == 1):\n",
    "            tf.gfile.Open.seek(self, self.tell() + position)\n",
    "        else:\n",
    "            raise FileError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab = np.asarray(list(\" '+-.ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"))\n",
    "vocab_to_int = {}\n",
    "\n",
    "def onehot(x):\n",
    "    x = np.asarray(x)\n",
    "    return np.tile(x, (32, 1)).T == vocab # 32 = vocab length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating AttentionSeq2Seq in mode=train\n",
      "INFO:tensorflow:\n",
      "AttentionSeq2Seq:\n",
      "  attention.class: AttentionLayerBahdanau\n",
      "  attention.params: {}\n",
      "  bridge.class: seq2seq.models.bridges.ZeroBridge\n",
      "  bridge.params: {}\n",
      "  decoder.class: seq2seq.decoders.AttentionDecoder\n",
      "  decoder.params: {}\n",
      "  embedding.dim: 100\n",
      "  embedding.init_scale: 0.04\n",
      "  embedding.share: false\n",
      "  encoder.class: seq2seq.encoders.BidirectionalRNNEncoder\n",
      "  encoder.params: {}\n",
      "  inference.beam_search.beam_width: 0\n",
      "  inference.beam_search.choose_successors_fn: choose_top_k\n",
      "  inference.beam_search.length_penalty_weight: 0.0\n",
      "  optimizer.clip_embed_gradients: 0.1\n",
      "  optimizer.clip_gradients: 5.0\n",
      "  optimizer.learning_rate: 0.0001\n",
      "  optimizer.lr_decay_rate: 0.99\n",
      "  optimizer.lr_decay_steps: 100\n",
      "  optimizer.lr_decay_type: ''\n",
      "  optimizer.lr_min_learning_rate: 1.0e-12\n",
      "  optimizer.lr_staircase: false\n",
      "  optimizer.lr_start_decay_at: 0\n",
      "  optimizer.lr_stop_decay_at: 2147483647\n",
      "  optimizer.name: Adam\n",
      "  optimizer.params: {}\n",
      "  optimizer.sync_replicas: 0\n",
      "  optimizer.sync_replicas_to_aggregate: 0\n",
      "  source.max_seq_len: 50\n",
      "  source.reverse: true\n",
      "  target.max_seq_len: 50\n",
      "  vocab_source: ''\n",
      "  vocab_target: ''\n",
      "\n",
      "Help on AttentionSeq2Seq in module seq2seq.models.attention_seq2seq object:\n",
      "\n",
      "class AttentionSeq2Seq(seq2seq.models.basic_seq2seq.BasicSeq2Seq)\n",
      " |  Sequence2Sequence model with attention mechanism.\n",
      " |  \n",
      " |  Args:\n",
      " |    source_vocab_info: An instance of `VocabInfo`\n",
      " |      for the source vocabulary\n",
      " |    target_vocab_info: An instance of `VocabInfo`\n",
      " |      for the target vocabulary\n",
      " |    params: A dictionary of hyperparameters\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AttentionSeq2Seq\n",
      " |      seq2seq.models.basic_seq2seq.BasicSeq2Seq\n",
      " |      seq2seq.models.seq2seq_model.Seq2SeqModel\n",
      " |      seq2seq.models.model_base.ModelBase\n",
      " |      seq2seq.configurable.Configurable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, mode, name='att_seq2seq')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  default_params()\n",
      " |      Returns a dictionary of default parameters for this model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from seq2seq.models.basic_seq2seq.BasicSeq2Seq:\n",
      " |  \n",
      " |  decode = func_wrapper(*args, **kwargs)\n",
      " |      Inner wrapper function\n",
      " |  \n",
      " |  encode = func_wrapper(*args, **kwargs)\n",
      " |      Inner wrapper function\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from seq2seq.models.seq2seq_model.Seq2SeqModel:\n",
      " |  \n",
      " |  batch_size(self, features, labels)\n",
      " |      Returns the batch size of the curren batch based on the passed\n",
      " |      features.\n",
      " |  \n",
      " |  compute_loss(self, decoder_output, _features, labels)\n",
      " |      Computes the loss for this model.\n",
      " |      \n",
      " |      Returns a tuple `(losses, loss)`, where `losses` are the per-batch\n",
      " |      losses and loss is a single scalar tensor to minimize.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from seq2seq.models.seq2seq_model.Seq2SeqModel:\n",
      " |  \n",
      " |  source_embedding\n",
      " |      Inner wrapper function\n",
      " |  \n",
      " |  target_embedding\n",
      " |      Inner wrapper function\n",
      " |  \n",
      " |  use_beam_search\n",
      " |      Returns true iff the model should perform beam search.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from seq2seq.models.model_base.ModelBase:\n",
      " |  \n",
      " |  __call__(self, features, labels, params)\n",
      " |      Creates the model graph. See the model_fn documentation in\n",
      " |      tf.contrib.learn.Estimator class for a more detailed explanation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from seq2seq.configurable.Configurable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  mode\n",
      " |      Returns a value in tf.contrib.learn.ModeKeys.\n",
      " |  \n",
      " |  params\n",
      " |      Returns a dictionary of parsed parameters.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6f134d884a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttentionSeq2Seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttentionSeq2Seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Vishal/vishal/gsoc/progress/seq2seq/seq2seq/models/model_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, labels, params)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Vishal/vishal/gsoc/progress/seq2seq/seq2seq/models/seq2seq_model.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, features, labels, params)\u001b[0m\n\u001b[1;32m    293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# Pre-process features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Vishal/vishal/gsoc/progress/seq2seq/seq2seq/models/seq2seq_model.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Create vocabulary lookup for source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0msource_vocab_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_id_to_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_word_to_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vocabulary_lookup_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_vocab_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Create vocabulary look for target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'path'"
     ]
    }
   ],
   "source": [
    "# Make a graph and it's session\n",
    "train_graph = tf.Graph()\n",
    "train_session = tf.InteractiveSession(graph=train_graph)\n",
    "\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    model_x = tf.placeholder()\n",
    "    model_y = tf.placeholder()\n",
    "    texts_lengths = tf.placeholder()\n",
    "    summaries_lengths = tf.placeholder()\n",
    "\n",
    "    model = seq2seq_model(input_data=model_x,\n",
    "                          target_data=model_y,\n",
    "                          keep_prob=keep_prob,\n",
    "                          text_length=texts_lengths,\n",
    "                          summary_length=summaries_lengths,\n",
    "                          max_output_length=max_output_length,\n",
    "                          vocab_size=len(vocab),\n",
    "                          rnn_size=rnn_size,\n",
    "                          num_layers=num_layers,\n",
    "                          vocab_to_int=vocab_to_int,\n",
    "                          batch_size=batch_size)\n",
    "    \n",
    "    with train_session as session():\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch_i in range(1, epochs+1):\n",
    "            while ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
